import streamlit as st
import pandas as pd
from supabase import create_client, Client
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

def check_password():
    """
    æ£€æŸ¥å¯†ç æ˜¯å¦æ­£ç¡®ã€‚
    å¦‚æœæ­£ç¡®ï¼Œè¿”å› Trueï¼›å¦‚æœä¸æ­£ç¡®ï¼Œæ˜¾ç¤ºè¾“å…¥æ¡†å¹¶åœæ­¢è¿è¡Œåç»­ä»£ç ã€‚
    """
    # 1. å¦‚æœå·²ç»éªŒè¯æˆåŠŸï¼Œç›´æ¥è¿”å› True
    if st.session_state.get("password_correct", False):
        return True

    # 2. å®šä¹‰å¯†ç éªŒè¯çš„å›è°ƒå‡½æ•°
    def password_entered():
        # æ£€æŸ¥è¾“å…¥å¯†ç æ˜¯å¦åŒ¹é… Secrets ä¸­çš„é…ç½®
        if st.session_state["password"] == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            # ä¸ºäº†å®‰å…¨ï¼ŒéªŒè¯ååˆ é™¤ session ä¸­çš„æ˜æ–‡å¯†ç 
            del st.session_state["password"] 
        else:
            st.session_state["password_correct"] = False

    # 3. æ˜¾ç¤ºå¯†ç è¾“å…¥æ¡†
    st.title("ğŸ”’ è¯·è¾“å…¥å¯†ç è®¿é—®")
    st.text_input(
        "Password", 
        type="password", 
        on_change=password_entered, 
        key="password"
    )
    
    # 4. å¦‚æœå¯†ç é”™è¯¯ï¼Œæç¤ºé”™è¯¯
    if "password_correct" in st.session_state and not st.session_state["password_correct"]:
        st.error("ğŸ˜• å¯†ç é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚")

    # 5. è¿”å› Falseï¼Œè¡¨ç¤ºæœªé€šè¿‡éªŒè¯
    return False

# --- æ‰§è¡Œæ£€æŸ¥ ---
if not check_password():
    st.stop()  # ğŸ›‘ æ ¸å¿ƒæ­¥éª¤ï¼šå¦‚æœæ²¡é€šè¿‡ï¼Œç›´æ¥åœæ­¢è¿è¡Œä¸‹é¢çš„æ‰€æœ‰ä»£ç 

# -----------------------------------------------------------------------------
# 1. Supabase Connection Setup
# -----------------------------------------------------------------------------
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]

@st.cache_resource
def init_connection():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_connection()

# -----------------------------------------------------------------------------
# 2. Data Fetching Functions
# -----------------------------------------------------------------------------
@st.cache_data(ttl=600) 
def fetch_data(table_name): 
    """Fetches all data from a Supabase table."""
    response = supabase.table(table_name).select("*").execute()
    data = response.data
    if data:
        return pd.DataFrame(data)
    return pd.DataFrame()


# -----------------------------------------------------------------------------
# HELPER FUNCTION: Calculate Aggregated Metrics for a Single Phase
# -----------------------------------------------------------------------------
def calculate_phase_metrics(phase_id, df):
    """Calculates aggregated GSC metrics (Clicks, Imp, CTR, Pos) for a single phase."""
    df_phase = df[df['Phase_id'] == phase_id]
    total_clicks = df_phase['Clicks'].sum()
    total_impressions = df_phase['Impressions'].sum()
    avg_position = df_phase['Position'].mean()
    avg_ctr = (total_clicks / total_impressions * 100) if total_impressions > 0 else 0
    
    return {
        'Phase_id': phase_id,
        'Clicks': total_clicks,
        'Impressions': total_impressions,
        'Position': avg_position,
        'CTR': avg_ctr
    }

# -----------------------------------------------------------------------------
# 3. Streamlit App Layout
# -----------------------------------------------------------------------------
st.set_page_config(page_title="SEO Phase Comparison Dashboard", layout="wide")

st.title("SEO Performance Dashboard")
st.markdown("Analysis is based on **Phase** segmentation.")

# Load Data
with st.spinner('Fetching data from Supabase...'):
    df_gsc = fetch_data("GSC")
    df_queries = fetch_data("Top_Queries")
    df_domains = fetch_data("Domains") 

# Initial Data Check
if df_gsc.empty:
    st.error("âŒ No GSC data found. Please use the Uploader script to add data.")
    st.stop()
if df_queries.empty:
    st.error("âŒ No Query data found. Please use the Uploader script to add data.")
    st.stop()


# -----------------------------------------------------------------------------
# SIDEBAR CONFIGURATION (Domain ID to Name Mapping)
# -----------------------------------------------------------------------------
st.sidebar.header("Configuration")

# 1. Create mapping: {id: name}
if not df_domains.empty and 'id' in df_domains.columns and 'domain_name' in df_domains.columns:
    domain_map = dict(zip(df_domains['id'], df_domains['domain_name']))
else:
    domain_map = {}

# 2. Get unique Domain IDs that actually have GSC data
available_domain_ids = sorted(df_gsc['Domain_id'].unique())
if not available_domain_ids:
    st.error("No domain data available in GSC table.")
    st.stop()

# 3. Create friendly labels for the dropdown
domain_options = {
    did: domain_map.get(did, f"ID: {did}") 
    for did in available_domain_ids
}

# 4. Selectbox shows Names, but the returned value is the ID (key)
selected_domain_id = st.sidebar.selectbox(
    "Select Domain", 
    options=available_domain_ids, 
    format_func=lambda x: domain_options[x] 
)

# Filter Data using the selected ID
domain_gsc = df_gsc[df_gsc['Domain_id'] == selected_domain_id]
df_queries_all = df_queries[df_queries['Domain_id'] == selected_domain_id]

unique_phases = sorted(domain_gsc['Phase_id'].unique())
if not unique_phases:
    st.error("No phases found for the selected domain.")
    st.stop()


# -----------------------------------------------------------------------------
# 5. Tab Layout (All Performance and Comparison)
# -----------------------------------------------------------------------------
tab_all, tab_comparison, tab_tiers, tab_strategy = st.tabs([
    "ğŸ“ˆ All Performance", 
    "âš”ï¸ Phase Comparison",
    "ğŸ† Position Tier Analysis",
    "ğŸ•µï¸ Strategy Validation" # <--- NEW TAB
])

# =============================================================================
# TAB 1: ALL PERFORMANCE
# =============================================================================
with tab_all:
    st.header(f"ğŸ“ˆ All Phase Performance Overview for {domain_options.get(selected_domain_id, 'Selected Domain')}")

    # Calculate metrics for ALL phases
    all_phases_metrics = [calculate_phase_metrics(pid, domain_gsc) for pid in unique_phases]
    df_all_phases = pd.DataFrame(all_phases_metrics)
    
    if df_all_phases.empty:
        st.warning("No performance data found to plot.")
    else:
        df_all_phases['Phase_id'] = df_all_phases['Phase_id'].astype(str)
        
        # 1. Clicks and Impressions Subplots
        fig_volume = make_subplots(rows=1, cols=2, subplot_titles=("Total Clicks Across Phases", "Total Impressions Across Phases"))
        
        fig_volume.add_trace(go.Bar(x=df_all_phases['Phase_id'], y=df_all_phases['Clicks'], name='Clicks', marker_color='skyblue'), row=1, col=1)
        fig_volume.add_trace(go.Bar(x=df_all_phases['Phase_id'], y=df_all_phases['Impressions'], name='Impressions', marker_color='orange'), row=1, col=2)
        
        fig_volume.update_layout(height=450, showlegend=False, title_text="Volume Trends: Clicks and Impressions")
        st.plotly_chart(fig_volume, use_container_width=True)
        
        # 2. CTR and Position Subplots
        fig_quality = make_subplots(rows=1, cols=2, subplot_titles=("Average CTR Across Phases", "Average Position Across Phases"))
        
        fig_quality.add_trace(go.Scatter(x=df_all_phases['Phase_id'], y=df_all_phases['CTR'], name='CTR', mode='lines+markers', line=dict(color='green', width=3)), row=1, col=1)
        fig_quality.add_trace(go.Scatter(x=df_all_phases['Phase_id'], y=df_all_phases['Position'], name='Position', mode='lines+markers', line=dict(color='red', width=3)), row=1, col=2)
        
        fig_quality.update_yaxes(autorange="reversed", title_text="Average Position (Lower is Better)", row=1, col=2)
        fig_quality.update_layout(height=450, showlegend=False, title_text="Quality Trends: CTR and Position")
        st.plotly_chart(fig_quality, use_container_width=True)
        
        st.subheader("Data Summary (All Phases)")
        st.dataframe(df_all_phases.style.format({
            "Clicks": "{:,.0f}", "Impressions": "{:,.0f}",
            "Position": "{:.1f}", "CTR": "{:.2f}%"
        }), use_container_width=True)


# =============================================================================
# TAB 2: PHASE COMPARISON
# =============================================================================
with tab_comparison:
    st.header("âš”ï¸ Phase-over-Phase Comparison")
    st.markdown("Compare key metrics between two distinct optimization phases.")

    col_a, col_b = st.columns(2)

    with col_a:
        phase_a = st.selectbox("Select Phase A (Baseline)", unique_phases, index=0, key='phase_a_select')
    with col_b:
        default_index_b = len(unique_phases) - 1 if len(unique_phases) > 1 else 0
        phase_b = st.selectbox("Select Phase B (Comparison)", unique_phases, index=default_index_b, key='phase_b_select')

    # Calculate metrics for both phases
    metrics_a = calculate_phase_metrics(phase_a, domain_gsc)
    metrics_b = calculate_phase_metrics(phase_b, domain_gsc)

    # Convert to DataFrames for easy merging/display
    df_metrics = pd.DataFrame([metrics_a, metrics_b]).set_index('Phase_id')

    # --- Metric Comparison ---
    st.subheader("GSC Core Metric Change: Phase B vs. Phase A")
    
    comp_cols = st.columns(4)
    metrics = ['Clicks', 'Impressions', 'CTR', 'Position']
    titles = ['Total Clicks', 'Total Impressions', 'Avg CTR', 'Avg Position']
    formats = ['{:.0f}', '{:.0f}', '{:.2f}%', '{:.1f}']
    
    for i, metric in enumerate(metrics):
        value_a = df_metrics.loc[phase_a, metric]
        value_b = df_metrics.loc[phase_b, metric]
        
        # Calculate Delta
        delta = value_b - value_a
        
        if metric == 'Position':
            if value_a == 0:
                delta_indicator = "N/A"
            else:
                delta_indicator = f"{delta:.1f}"
                if delta < 0:
                    delta_indicator += " (Better)"
                elif delta > 0:
                    delta_indicator += " (Worse)"
                else:
                    delta_indicator = "No Change"
        elif value_a != 0:
             delta_pct = (delta / value_a * 100)
             delta_indicator = f"{delta_pct:+.2f}%"
        else:
            delta_indicator = f"{delta:+,}"

        with comp_cols[i]:
            st.metric(label=titles[i], value=formats[i].format(value_b), delta=delta_indicator)

    st.divider()
    
    # --- Queries Control ---
    st.subheader("Query Mover Analysis")
    max_rows = st.slider(
        "Max Number of Top/Bottom Queries to Display", 
        min_value=5, 
        max_value=30, 
        value=10, 
        step=5
    )
    st.divider()
    
    # Helper to Aggregate
    def aggregate_queries(phase_id, df_q):
        df_phase = df_q[df_q['Phase_id'] == phase_id]
        return df_phase.groupby('Top_Queries').agg({
            'Clicks': 'sum',
            'Impressions': 'sum',
            'Position': 'mean'
        }).reset_index().rename(columns={
            'Clicks': f'Clicks_{phase_id}',
            'Impressions': f'Impressions_{phase_id}',
            'Position': f'Position_{phase_id}',
        })

    # Define MAX_RANK for calculation consistency (Treat 0 position as 100 for delta calculation)
    MAX_RANK = 100 
    
    # Merge Phase A and Phase B Query Data
    df_q_a = aggregate_queries(phase_a, df_queries_all)
    df_q_b = aggregate_queries(phase_b, df_queries_all)
    
    df_merged = pd.merge(
        df_q_a, 
        df_q_b, 
        on='Top_Queries', 
        how='outer'
    ).fillna(0)
    
    # Calculate all necessary deltas
    df_merged['Click_Delta'] = df_merged[f'Clicks_{phase_b}'] - df_merged[f'Clicks_{phase_a}']
    df_merged['Imp_Delta'] = df_merged[f'Impressions_{phase_b}'] - df_merged[f'Impressions_{phase_a}']
    
    df_merged[f'CTR_{phase_a}'] = (df_merged[f'Clicks_{phase_a}'] / df_merged[f'Impressions_{phase_a}'] * 100).fillna(0)
    df_merged[f'CTR_{phase_b}'] = (df_merged[f'Clicks_{phase_b}'] / df_merged[f'Impressions_{phase_b}'] * 100).fillna(0)
    df_merged['CTR_Delta'] = df_merged[f'CTR_{phase_b}'] - df_merged[f'CTR_{phase_a}']

    # --- REVISED POSITION DELTA LOGIC ---
    # 1. Create temporary calculation columns where 0 is replaced by MAX_RANK (100)
    pos_a_calc = df_merged[f'Position_{phase_a}'].replace(0, MAX_RANK)
    pos_b_calc = df_merged[f'Position_{phase_b}'].replace(0, MAX_RANK)
    
    # 2. Calculate Pos_Delta: Pos_B - Pos_A. Negative delta means improvement.
    df_merged['Pos_Delta'] = pos_b_calc - pos_a_calc

    # -------------------------------------------------------------
    # Analysis 1: Clicks & Impressions Movers (Uses st.table and max_rows)
    # -------------------------------------------------------------
    st.subheader("Query Volume Movers: Clicks & Impressions")

    col_click_movers, col_imp_movers = st.columns(2)

    top_gainers_click = df_merged.sort_values(by='Click_Delta', ascending=False).head(max_rows)
    top_losers_click = df_merged.sort_values(by='Click_Delta', ascending=True).head(max_rows)

    with col_click_movers:
        st.success(f"Top {max_rows} Click Gainers (Phase {phase_b} vs Phase {phase_a})")
        st.table(top_gainers_click[['Top_Queries', f'Clicks_{phase_a}', f'Clicks_{phase_b}', 'Click_Delta']].style.format({
            f'Clicks_{phase_a}': "{:,.0f}", f'Clicks_{phase_b}': "{:,.0f}", 'Click_Delta': "{:+,}"
        }))
        st.error(f"Top {max_rows} Click Losers (Phase {phase_b} vs Phase {phase_a})")
        st.table(top_losers_click[['Top_Queries', f'Clicks_{phase_a}', f'Clicks_{phase_b}', 'Click_Delta']].style.format({
            f'Clicks_{phase_a}': "{:,.0f}", f'Clicks_{phase_b}': "{:,.0f}", 'Click_Delta': "{:+,}"
        }))

    top_gainers_imp = df_merged.sort_values(by='Imp_Delta', ascending=False).head(max_rows)
    top_losers_imp = df_merged.sort_values(by='Imp_Delta', ascending=True).head(max_rows)

    with col_imp_movers:
        st.info(f"Top {max_rows} Impression Gainers (Phase {phase_b} vs Phase {phase_a})")
        st.table(top_gainers_imp[['Top_Queries', f'Impressions_{phase_a}', f'Impressions_{phase_b}', 'Imp_Delta']].style.format({
            f'Impressions_{phase_a}': "{:,.0f}", f'Impressions_{phase_b}': "{:,.0f}", 'Imp_Delta': "{:+,}"
        }))
        st.warning(f"Top {max_rows} Impression Losers (Phase {phase_b} vs Phase {phase_a})")
        st.table(top_losers_imp[['Top_Queries', f'Impressions_{phase_a}', f'Impressions_{phase_b}', 'Imp_Delta']].style.format({
            f'Impressions_{phase_a}': "{:,.0f}", f'Impressions_{phase_b}': "{:,.0f}", 'Imp_Delta': "{:+,}"
        }))

    st.divider()

# =============================================================================
# TAB 3: POSITION TIER ANALYSIS (ENHANCED + CLEAN EXPANDER REVISION)
# =============================================================================
with tab_tiers:
    # Tooltip Definitions for use inside the component
    TOOLTIP_S_IMPROVERS_EXP = "âœ… **Tier S** åŒ…å«ï¼š**æ–°æ’å**ã€**è¿›å…¥ Top 3 (S++)**ï¼Œä»¥åŠ**å¤§å¹…åº¦æå‡ 10+ ä½ (S+)**ã€‚è¿™æ˜¯æœ€é«˜ä»·å€¼çš„è¿›æ­¥ã€‚"
    TOOLTIP_A_IMPROVERS_EXP = "ğŸ”¥ **Tier A (Top 10 Solid)**ï¼šæœ€ç»ˆæ’åå‰ 10 (Pos â‰¤ 10) ä¸”æœ‰ 3+ ä½å®è´¨æ€§è¿›æ­¥çš„æŸ¥è¯¢ã€‚"
    TOOLTIP_B_IMPROVERS_EXP = "âœ¨ **Tier B (General Jump)**ï¼šæ‰€æœ‰å…¶ä»–æœ‰æ’åè¿›æ­¥ (Delta < 0) ä½†æœªè¾¾åˆ°æ›´é«˜ Tier æ ‡å‡†çš„æŸ¥è¯¢ã€‚"
    TOOLTIP_S_DECLINERS_EXP = "ğŸš¨ **Decliner S (Crash/Lost)**ï¼šæ’å**å¤§å¹…åº¦ä¸‹é™ 10+ ä½ (Delta â‰¥ 10)** æˆ–**æ’åå®Œå…¨ä¸¢å¤± (Pos_B = 0)**ã€‚è¯·ä¼˜å…ˆå¤„ç†æ­¤é¡¹ã€‚"
    TOOLTIP_A_DECLINERS_EXP = "ğŸ“‰ **Decliner A (Top 10 Drop)**ï¼šä»å…³é”® Top 10 åŒºåŸŸ (Pos_A â‰¤ 10) æ‰å‡º 3+ ä½ä»¥ä¸Šçš„æŸ¥è¯¢ã€‚"
    TOOLTIP_B_DECLINERS_EXP = "âš ï¸ **Decliner B (Minor Drop)**ï¼šæ‰€æœ‰å…¶ä»–æœ‰æ’ååé€€ (Delta > 0) ä½†æœªè¾¾åˆ°æ›´é«˜ Decliner Tier æ ‡å‡†çš„æŸ¥è¯¢ã€‚"


    st.header("ğŸ† Position Improvement & Drop Analysis (Enhanced Tiers)")
    st.markdown("Detailed breakdown of ranking changes, focusing on high-impact Top 3 and Top 10 movements.")
    
    # Define a constant for rank calculation (e.g., treating a lost rank as position 100)
    MAX_RANK = 100 

    col_t_a, col_t_b = st.columns(2)
    with col_t_a:
        tier_phase_a = st.selectbox("Select Phase A (Baseline)", unique_phases, index=0, key='tier_a')
    with col_t_b:
        default_index_b_tier = len(unique_phases) - 1 if len(unique_phases) > 1 else 0
        tier_phase_b = st.selectbox("Select Phase B (Comparison)", unique_phases, index=default_index_b_tier, key='tier_b')

    # Reuse aggregation logic (The function 'aggregate_queries' is defined in TAB 2)
    tier_df_a = aggregate_queries(tier_phase_a, df_queries_all)
    tier_df_b = aggregate_queries(tier_phase_b, df_queries_all)
    
    tier_merged = pd.merge(tier_df_a, tier_df_b, on='Top_Queries', how='outer').fillna(0)
    
    # -----------------------------------------------------------
    # DATA PREP & TIER CLASSIFICATION
    # -----------------------------------------------------------
    pos_a_calc = tier_merged[f'Position_{tier_phase_a}'].replace(0, MAX_RANK)
    pos_b_calc = tier_merged[f'Position_{tier_phase_b}'].replace(0, MAX_RANK)
    tier_merged['Pos_Delta'] = pos_b_calc - pos_a_calc
    
    tier_analysis_df = tier_merged[
        (tier_merged[f'Position_{tier_phase_a}'] > 0) | 
        (tier_merged[f'Position_{tier_phase_b}'] > 0)
    ].copy()
    
    pos_a_filtered_calc = tier_analysis_df[f'Position_{tier_phase_a}'].replace(0, MAX_RANK)
    pos_b_filtered_calc = tier_analysis_df[f'Position_{tier_phase_b}'].replace(0, MAX_RANK)
    tier_analysis_df['Pos_Delta'] = pos_b_filtered_calc - pos_a_filtered_calc


    def categorize_tier_enhanced(row):
        pos_a = row[f'Position_{tier_phase_a}']
        pos_b = row[f'Position_{tier_phase_b}']
        delta = row['Pos_Delta'] 
        
        if pos_a == 0 and pos_b > 0: 
            return 'Tier S (New Rank)'
            
        if pos_b > 0 and pos_b <= 3 and pos_a > 3:
            return 'Tier S++ (Top 3 Win)'
            
        if delta <= -10: 
            return 'Tier S+ (Jump 10+)'
            
        if pos_b > 0 and pos_b <= 10 and delta <= -3:
            return 'Tier A (Top 10 Solid)'
            
        if delta < 0:
            return 'Tier B (General Jump)'
            
        if delta >= 10: 
            return 'Decliner S (Crash/Lost)'
            
        if pos_a <= 10 and delta >= 3:
            return 'Decliner A (Top 10 Drop)'
            
        if delta > 0:
            return 'Decliner B (General Drop)'
        
        return 'No Change'

    tier_analysis_df['Tier_Class'] = tier_analysis_df.apply(categorize_tier_enhanced, axis=1)

# -----------------------------------------------------------
    # SUMMARY METRICS (UI ENHANCED)
    # -----------------------------------------------------------
    st.markdown("### ğŸ“Š Tier Summary (Enhanced Analysis)")
    
    # 1. Calculate Totals & Aggregates
    total_keywords = len(tier_analysis_df)
    tier_counts = tier_analysis_df['Tier_Class'].value_counts()
    
    # Counts for Improvers
    count_tier_s_all = int(
        tier_counts.get('Tier S (New Rank)', 0) + 
        tier_counts.get('Tier S++ (Top 3 Win)', 0) + 
        tier_counts.get('Tier S+ (Jump 10+)', 0)
    )
    count_tier_a = int(tier_counts.get('Tier A (Top 10 Solid)', 0))
    count_tier_b = int(tier_counts.get('Tier B (General Jump)', 0))
    total_improvers = count_tier_s_all + count_tier_a + count_tier_b
    
    # Counts for Decliners
    count_crash = int(tier_counts.get('Decliner S (Crash/Lost)', 0))
    count_major_drop = int(tier_counts.get('Decliner A (Top 10 Drop)', 0))
    count_minor_drop = int(tier_counts.get('Decliner B (General Drop)', 0))
    total_decliners = count_crash + count_major_drop + count_minor_drop
    
    count_no_change = int(tier_counts.get('No Change', 0))

    # 2. Top Level Stats (Hero Section)
    hero_c1, hero_c2, hero_c3, hero_c4 = st.columns(4)
    
    with hero_c1:
        st.metric("ğŸ“¦ Total Keywords", f"{total_keywords}", help="Total unique queries analyzed between these two phases.")
    with hero_c2:
        win_rate = (total_improvers / total_keywords * 100) if total_keywords > 0 else 0
        st.metric("ğŸ“ˆ Total Improvers", f"{total_improvers}", f"{win_rate:.1f}% Ratio")
    with hero_c3:
        loss_rate = (total_decliners / total_keywords * 100) if total_keywords > 0 else 0
        st.metric("ğŸ“‰ Total Decliners", f"{total_decliners}", f"-{loss_rate:.1f}% Ratio", delta_color="inverse")
    with hero_c4:
        st.metric("â– No Change", f"{count_no_change}", help="Queries with rank delta = 0")

    st.divider()

    # 3. Visual Breakdown (Chart + Detailed Metrics)
    viz_col, metric_col = st.columns([1, 2])

    with viz_col:
        # Prepare Data for Pie Chart
        pie_labels = ['Elite/Major Wins (Tier S)', 'Solid Wins (Tier A)', 'General Wins (Tier B)', 'No Change', 'Minor Drops', 'Major Drops', 'Crashes']
        pie_values = [count_tier_s_all, count_tier_a, count_tier_b, count_no_change, count_minor_drop, count_major_drop, count_crash]
        pie_colors = ['#1f77b4', '#2ca02c', '#98df8a', '#d3d3d3', '#ff9896', '#d62728', '#8c000f'] # Blue, Green, LightGreen, Gray, LightRed, Red, DarkRed
        
        # Filter out zeros to clean up chart
        chart_data = {'Label': [], 'Value': [], 'Color': []}
        for l, v, c in zip(pie_labels, pie_values, pie_colors):
            if v > 0:
                chart_data['Label'].append(l)
                chart_data['Value'].append(v)
                chart_data['Color'].append(c)

        if chart_data['Value']:
            fig_tier = go.Figure(data=[go.Pie(
                labels=chart_data['Label'], 
                values=chart_data['Value'], 
                hole=.4,
                marker=dict(colors=chart_data['Color']),
                textinfo='label+percent',
                showlegend=False
            )])
            fig_tier.update_layout(
                title_text="Tier Distribution",
                margin=dict(t=30, b=0, l=0, r=0),
                height=300
            )
            st.plotly_chart(fig_tier, use_container_width=True)
        else:
            st.info("No data to visualize.")

    with metric_col:
        st.subheader("Detailed Breakdown")
        
        # Organize into two rows: Gains vs Losses
        m_row1_c1, m_row1_c2, m_row1_c3 = st.columns(3)
        with m_row1_c1:
            st.markdown("##### ğŸš€ Tier S (Elite)")
            st.markdown(f"<h2 style='margin:0; color:#1f77b4'>{count_tier_s_all}</h2>", unsafe_allow_html=True)
            st.caption("New / Top 3 / Jump 10+")
        with m_row1_c2:
            st.markdown("##### ğŸ”¥ Tier A (Solid)")
            st.markdown(f"<h2 style='margin:0; color:#2ca02c'>{count_tier_a}</h2>", unsafe_allow_html=True)
            st.caption("Top 10 Growth")
        with m_row1_c3:
            st.markdown("##### âœ¨ Tier B (General)")
            st.markdown(f"<h2 style='margin:0; color:#98df8a'>{count_tier_b}</h2>", unsafe_allow_html=True)
            st.caption("Minor Improvements")

        st.markdown("---") # Small separator

        m_row2_c1, m_row2_c2, m_row2_c3 = st.columns(3)
        with m_row2_c1:
            st.markdown("##### ğŸš¨ Crash (Tier S)")
            st.markdown(f"<h2 style='margin:0; color:#8c000f'>{count_crash}</h2>", unsafe_allow_html=True)
            st.caption("Lost / Drop 10+")
        with m_row2_c2:
            st.markdown("##### ğŸ“‰ Major Drop (Tier A)")
            st.markdown(f"<h2 style='margin:0; color:#d62728'>{count_major_drop}</h2>", unsafe_allow_html=True)
            st.caption("Top 10 Fall")
        with m_row2_c3:
            st.markdown("##### âš ï¸ Minor Drop (Tier B)")
            st.markdown(f"<h2 style='margin:0; color:#ff9896'>{count_minor_drop}</h2>", unsafe_allow_html=True)
            st.caption("General Decline")
    
    st.divider()

    # -----------------------------------------------------------
    # EXPANDABLE TABLES (FIXED HTML RENDERING - Using internal description)
    # -----------------------------------------------------------
    common_cols_display = ['Top_Queries', f'Position_{tier_phase_a}', f'Position_{tier_phase_b}', 'Pos_Delta']
    col_format = {
        f'Position_{tier_phase_a}': "{:.1f}", 
        f'Position_{tier_phase_b}': "{:.1f}", 
        'Pos_Delta': "{:+.1f}",
    }
    
    # --- IMPROVERS ---
    st.subheader("âœ… Improvers")
    
    # Tier S (Combine Elite, Major Jump, and New)
    s_tiers = ['Tier S (New Rank)', 'Tier S++ (Top 3 Win)', 'Tier S+ (Jump 10+)']
    df_s_combined = tier_analysis_df[tier_analysis_df['Tier_Class'].isin(s_tiers)].sort_values('Pos_Delta', ascending=True)
    
    # Expander with explicit title and internal description
    with st.expander(f"ğŸš€ Tier S: Elite Movers (Count: {len(df_s_combined)})", expanded=False):
        st.markdown(TOOLTIP_S_IMPROVERS_EXP)
        if not df_s_combined.empty:
            st.table(df_s_combined[common_cols_display + ['Tier_Class']].head(50).style.format(col_format))
        else:
            st.info("No elite improvers found.")

    # Tier A
    df_a = tier_analysis_df[tier_analysis_df['Tier_Class'] == 'Tier A (Top 10 Solid)'].sort_values('Pos_Delta', ascending=True)
    with st.expander(f"ğŸ”¥ Tier A: Top 10 Solid Improvers (Count: {len(df_a)})", expanded=False):
        st.markdown(TOOLTIP_A_IMPROVERS_EXP)
        if not df_a.empty:
            st.table(df_a[common_cols_display].head(50).style.format(col_format))
        else:
            st.info("No solid Top 10 improvers found.")

    # Tier B
    df_b = tier_analysis_df[tier_analysis_df['Tier_Class'] == 'Tier B (General Jump)'].sort_values('Pos_Delta', ascending=True)
    with st.expander(f"âœ¨ Tier B: General Improvers (Count: {len(df_b)})", expanded=False):
        st.markdown(TOOLTIP_B_IMPROVERS_EXP)
        if not df_b.empty:
            st.table(df_b[common_cols_display].head(50).style.format(col_format))
        else:
            st.info("No general improvers found.")

    # --- DECLINERS ---
    st.subheader("ğŸ”» Decliners")

    # Decliner S (Crash/Lost)
    df_d_s = tier_analysis_df[tier_analysis_df['Tier_Class'] == 'Decliner S (Crash/Lost)'].sort_values('Pos_Delta', ascending=False)
    with st.expander(f"ğŸš¨ Crash: Dropped 10+ Ranks or Lost (Count: {len(df_d_s)})", expanded=True): 
        st.markdown(TOOLTIP_S_DECLINERS_EXP)
        if not df_d_s.empty:
            st.table(df_d_s[common_cols_display].head(50).style.format(col_format))
        else:
            st.info("No crash decliners found.")

    # Decliner A (Top 10 Drop)
    df_d_a = tier_analysis_df[tier_analysis_df['Tier_Class'] == 'Decliner A (Top 10 Drop)'].sort_values('Pos_Delta', ascending=False)
    with st.expander(f"ğŸ“‰ Major Drop: Drop from Top 10 (Count: {len(df_d_a)})", expanded=False):
        st.markdown(TOOLTIP_A_DECLINERS_EXP)
        if not df_d_a.empty:
            st.table(df_d_a[common_cols_display].head(50).style.format(col_format))
        else:
            st.info("No major Top 10 drops found.")

    # Decliner B (General Drop)
    df_d_b = tier_analysis_df[tier_analysis_df['Tier_Class'] == 'Decliner B (General Drop)'].sort_values('Pos_Delta', ascending=False)
    with st.expander(f"âš ï¸ Minor Drop: General Decliners (Count: {len(df_d_b)})", expanded=False):
        st.markdown(TOOLTIP_B_DECLINERS_EXP)
        if not df_d_b.empty:
            st.table(df_d_b[common_cols_display].head(50).style.format(col_format))
        else:
            st.info("No general decliners found.")

# =============================================================================
# TAB 4: STRATEGY VALIDATION (ROI & RISK SCORECARD)
# =============================================================================
with tab_strategy:
    st.header("ğŸ•µï¸ Strategy Health Scorecard")
    st.markdown("é€šè¿‡ **æˆåŠŸç‡ (Percentage)** å®è§‚åˆ¤æ–­ç‚¹å‡»ç­–ç•¥æ˜¯å¦æœ‰æ•ˆï¼Œè€Œéçº ç»“äºå•ä¸ªå…³é”®è¯ã€‚")

    # 1. Select Phases
    col_s_a, col_s_b = st.columns(2)
    with col_s_a:
        st_phase_a = st.selectbox("Baseline Phase (Before/Start)", unique_phases, index=0, key='st_a')
    with col_s_b:
        default_index_st = len(unique_phases) - 1 if len(unique_phases) > 1 else 0
        st_phase_b = st.selectbox("Comparison Phase (Current/End)", unique_phases, index=default_index_st, key='st_b')

    # 2. Data Preparation
    MAX_RANK = 100
    
    # Aggregate Data (Independent to ensure clean calculation)
    st_df_a = df_queries_all[df_queries_all['Phase_id'] == st_phase_a].groupby('Top_Queries').agg({
        'Clicks': 'sum', 'Impressions': 'sum', 'Position': 'mean'
    }).reset_index()
    
    st_df_b = df_queries_all[df_queries_all['Phase_id'] == st_phase_b].groupby('Top_Queries').agg({
        'Clicks': 'sum', 'Impressions': 'sum', 'Position': 'mean'
    }).reset_index()

    st_merged = pd.merge(st_df_a, st_df_b, on='Top_Queries', how='outer', suffixes=('_A', '_B')).fillna(0)

    # Metrics Calculation
    st_merged['Pos_A_Calc'] = st_merged['Position_A'].replace(0, MAX_RANK)
    st_merged['Pos_B_Calc'] = st_merged['Position_B'].replace(0, MAX_RANK)
    st_merged['Pos_Delta'] = st_merged['Pos_B_Calc'] - st_merged['Pos_A_Calc'] # Negative is Good
    st_merged['Imp_Delta'] = st_merged['Impressions_B'] - st_merged['Impressions_A']
    
    st_merged['CTR_A'] = (st_merged['Clicks_A'] / st_merged['Impressions_A'] * 100).fillna(0)
    st_merged['CTR_B'] = (st_merged['Clicks_B'] / st_merged['Impressions_B'] * 100).fillna(0)
    st_merged['CTR_Delta'] = st_merged['CTR_B'] - st_merged['CTR_A']

    # Total Queries analyzed (exclude noise with 0 impressions in both phases if needed, but let's keep all for now)
    st_analysis_df = st_merged[(st_merged['Impressions_A'] > 0) | (st_merged['Impressions_B'] > 0)].copy()
    total_queries = len(st_analysis_df)

    if total_queries == 0:
        st.warning("No data available for analysis.")
        st.stop()

    # -----------------------------------------------------------
    # CALCULATE PERCENTAGES (The "Scorecard" Logic)
    # -----------------------------------------------------------
    
    # Criteria 1: True ROI (Rank Improved AND Impressions Grew)
    # Pos_Delta < 0 (Improved) AND Imp_Delta > 0 (Growth)
    true_wins_df = st_analysis_df[
        (st_analysis_df['Pos_Delta'] < 0) & 
        (st_analysis_df['Imp_Delta'] > 0)
    ]
    count_wins = len(true_wins_df)
    pct_wins = (count_wins / total_queries) * 100

    # Criteria 2: Risk (CTR Boosted > 3% BUT Rank Dropped)
    # CTR_Delta > 3 (High Boost) AND Pos_Delta > 0 (Dropped)
    risky_df = st_analysis_df[
        (st_analysis_df['CTR_Delta'] > 3) & 
        (st_analysis_df['Pos_Delta'] > 0)
    ]
    count_risk = len(risky_df)
    pct_risk = (count_risk / total_queries) * 100

    # Criteria 3: Ineffective (CTR Boosted > 3% BUT Rank No Change or Minimal Drop)
    # CTR_Delta > 3 AND Pos_Delta == 0 (Stagnant)
    ineffective_df = st_analysis_df[
        (st_analysis_df['CTR_Delta'] > 3) & 
        (st_analysis_df['Pos_Delta'] == 0)
    ]
    count_ineffective = len(ineffective_df)
    pct_ineffective = (count_ineffective / total_queries) * 100

    # -----------------------------------------------------------
    # DISPLAY SCORECARD
    # -----------------------------------------------------------
    st.subheader("ğŸ“Š ç­–ç•¥å¥åº·åº¦ (Strategy Health)")
    
    sc1, sc2, sc3 = st.columns(3)
    
    with sc1:
        st.metric(
            label="âœ… çœŸå®æœ‰æ•ˆç‡ (True Win Rate)",
            value=f"{pct_wins:.1f}%",
            delta=f"{count_wins}/{total_queries} è¯",
            help="æ’åæå‡ (Pos Up) ä¸” çœŸå®æ›å…‰å¢é•¿ (Imp Up) çš„å…³é”®è¯å æ¯”ã€‚è¶Šé«˜è¶Šå¥½ï¼Œè¯´æ˜ç‚¹å‡»å¸¦æ¥äº†çœŸå®æµé‡ã€‚"
        )
    
    with sc2:
        st.metric(
            label="âš ï¸ é£é™©/ç¿»è½¦ç‡ (Risk Rate)",
            value=f"{pct_risk:.1f}%",
            delta=f"{count_risk}/{total_queries} è¯",
            delta_color="inverse", # Red if positive (bad)
            help="CTR æå‡è¶…è¿‡ 3% ä½†æ’ååè€Œä¸‹è·Œçš„å…³é”®è¯å æ¯”ã€‚å¦‚æœæ­¤å€¼è¿‡é«˜ (>10%)ï¼Œè¯·ç«‹å³æš‚åœç­–ç•¥ã€‚"
        )
        
    with sc3:
        st.metric(
            label="ğŸ’¨ æ— æ•ˆæ¶ˆè€—ç‡ (Wasted Rate)",
            value=f"{pct_ineffective:.1f}%",
            delta=f"{count_ineffective}/{total_queries} è¯",
            delta_color="off",
            help="CTR æå‡è¶…è¿‡ 3% ä½†æ’åçº¹ä¸ä¸åŠ¨çš„å…³é”®è¯ã€‚è¯´æ˜ç”±äºç«äº‰æˆ–ç®—æ³•è¿‡æ»¤ï¼ŒæŠ•å…¥æœªäº§ç”Ÿæ•ˆæœã€‚"
        )

    st.progress(pct_wins / 100)
    st.caption(f"å½“å‰ç­–ç•¥æœ‰æ•ˆæ€§è¿›åº¦æ¡: {pct_wins:.1f}% çš„è¯äº§ç”Ÿäº†æ­£å‘æ”¶ç›Š")

    # =========================================================================
    # NEW: æ·±åº¦ä¸å¼ºåº¦åˆ†æ (è§£å†³ "èµ¢å°è¾“å¤§" çš„æ‹…å¿§)
    # =========================================================================
    st.markdown("#### âš–ï¸ å¼ºåº¦ä¸æ·±åº¦åˆ†æ (Magnitude Check)")
    st.info("æ­¤åŒºåŸŸç”¨äºéªŒè¯ï¼š**ä¸Šæ¶¨æ˜¯å¦åªæ˜¯å¾®æ¶¨ï¼Œä¸‹è·Œæ˜¯å¦æ˜¯æš´è·Œï¼Ÿ**")

    # 1. è®¡ç®—å¹³å‡å¹…åº¦
    # èµ¢å®¶ï¼šå–ç»å¯¹å€¼è®¡ç®—å¹³å‡æå‡äº†å¤šå°‘ä½
    avg_win_depth = abs(true_wins_df['Pos_Delta'].mean()) if not true_wins_df.empty else 0
    # è¾“å®¶(é£é™©è¯)ï¼šè®¡ç®—å¹³å‡ä¸‹é™äº†å¤šå°‘ä½
    avg_loss_depth = risky_df['Pos_Delta'].mean() if not risky_df.empty else 0

    # 2. è®¡ç®—æ€»æ’åç›ˆäº (Total Rank P&L)
    # æ€»å…±æå‡äº†å¤šå°‘ä¸ªåæ¬¡ vs æ€»å…±ä¸¢å¤±äº†å¤šå°‘ä¸ªåæ¬¡
    total_ranks_gained = abs(true_wins_df['Pos_Delta'].sum()) if not true_wins_df.empty else 0
    total_ranks_lost = risky_df['Pos_Delta'].sum() if not risky_df.empty else 0
    net_rank_change = total_ranks_gained - total_ranks_lost # å› ä¸ºlostæ˜¯æ­£æ•°(rankå˜å¤§)ï¼Œæ‰€ä»¥è¿™é‡Œç›¸å‡ä»£è¡¨ç›ˆäº

    # 3. å±•ç¤º Metrics
    mag_col1, mag_col2, mag_col3 = st.columns(3)

    with mag_col1:
        st.metric(
            label="å¹³å‡æå‡å¹…åº¦ (Avg Up)",
            value=f"{avg_win_depth:.1f} ä½",
            help="å¹³å‡æ¯ä¸ªâ€œçœŸå®å¢é•¿è¯â€æå‡äº†å¤šå°‘ä¸ªåæ¬¡ã€‚"
        )

    with mag_col2:
        is_crash = avg_loss_depth > (avg_win_depth * 1.5) # å¦‚æœè·Œå¹…æ˜¯æ¶¨å¹…çš„1.5å€ï¼Œæ ‡çº¢
        st.metric(
            label="å¹³å‡ä¸‹è·Œå¹…åº¦ (Avg Down)",
            value=f"{avg_loss_depth:.1f} ä½",
            delta="âš ï¸ è·Œå¹…è¿‡æ·±" if is_crash else "å¹…åº¦å¯æ§",
            delta_color="inverse" if is_crash else "normal",
            help="å¹³å‡æ¯ä¸ªâ€œé£é™©è¯â€ä¸‹é™äº†å¤šå°‘ä¸ªåæ¬¡ã€‚"
        )

    with mag_col3:
        # å‡€æ’åç›ˆäº
        rank_delta_label = "ğŸŸ¢ å‡€èµšåæ¬¡" if total_ranks_gained > total_ranks_lost else "ğŸ”´ å‡€äºåæ¬¡"
        st.metric(
            label="å…¨ç›˜åæ¬¡ç›ˆäº (Net Rank P&L)",
            value=f"{int(total_ranks_gained - total_ranks_lost)} ä½",
            delta=f"èµš {int(total_ranks_gained)} vs äº {int(total_ranks_lost)}",
            help="èµ¢å®¶æå‡çš„æ€»åæ¬¡å‡å»è¾“å®¶è·Œæ‰çš„æ€»åæ¬¡ã€‚å¦‚æœä¸ºè´Ÿï¼Œè¯´æ˜è™½ç„¶èµ¢çš„è¯å¤šï¼Œä½†è·Œæ‰çš„åæ¬¡æ›´å¤šã€‚"
        )

    # 4. æ™ºèƒ½é¢„è­¦ (Severity Warning)
    if is_crash:
        st.error(
            f"â›” **ä¸¥é‡è­¦å‘Š**: è™½ç„¶æœ‰ {pct_wins:.1f}% çš„èƒœç‡ï¼Œä½†å¹³å‡è·Œå¹… ({avg_loss_depth:.1f}) è¿œå¤§äºå¹³å‡æ¶¨å¹… ({avg_win_depth:.1f})ã€‚"
            "è¿™æ„å‘³ç€ä½ åœ¨é€šè¿‡ç‰ºç‰²å°‘æ•°è¯çš„**å‰§çƒˆ**æ’åæ¥æ¢å–å¤šæ•°è¯çš„**å¾®å¼±**ä¸Šæ¶¨ã€‚è¯·æ£€æŸ¥æ˜¯å¦æœ‰ç‚¹é”™äº†å…³é”®å¤§è¯ã€‚"
        )
    elif avg_loss_depth > avg_win_depth:
        st.warning("âš ï¸ **æ³¨æ„**: å¹³å‡è·Œå¹…ç•¥å¤§äºå¹³å‡æ¶¨å¹…ï¼Œç­–ç•¥æ”¶ç›Šå¯èƒ½è¢«ä¸‹è·ŒæŠµæ¶ˆã€‚")
    else:
        st.success("âœ… **å¥åº·**: å¹³å‡æ¶¨å¹…å¤§äºè·Œå¹…ï¼Œä¸”å‡€åæ¬¡ä¸ºæ­£ï¼Œç­–ç•¥åœ¨ç¨³æ­¥æ¨è¿›ã€‚")    

    st.divider()

    # -----------------------------------------------------------
    # DETAILED DRILL-DOWN (Expanders)
    # -----------------------------------------------------------
    col_d1, col_d2 = st.columns(2)

    with col_d1:
        st.subheader("ğŸ’ çœŸå®å¢é•¿è¯ (True Wins)")
        with st.expander(f"æŸ¥çœ‹ {count_wins} ä¸ªæœ‰æ•ˆå…³é”®è¯æ˜ç»†", expanded=True):
            if not true_wins_df.empty:
                st.dataframe(
                    true_wins_df[['Top_Queries', 'Pos_Delta', 'Imp_Delta', 'CTR_Delta']].sort_values('Imp_Delta', ascending=False).style.format({
                        'Pos_Delta': "{:.1f}", 'Imp_Delta': "{:+,.0f}", 'CTR_Delta': "{:+.1f}%"
                    }),
                    use_container_width=True
                )
            else:
                st.info("æš‚æ— ç¬¦åˆæ¡ä»¶çš„å…³é”®è¯ã€‚")

    with col_d2:
        st.subheader("ğŸš¨ é£é™©é¢„è­¦è¯ (Risks)")
        with st.expander(f"æŸ¥çœ‹ {count_risk} ä¸ªé£é™©å…³é”®è¯æ˜ç»†", expanded=True):
            if not risky_df.empty:
                st.dataframe(
                    risky_df[['Top_Queries', 'Pos_Delta', 'CTR_Delta', 'Position_B']].sort_values('Pos_Delta', ascending=False).style.format({
                        'Pos_Delta': "{:+.1f}", 'CTR_Delta': "{:+.1f}%", 'Position_B': "{:.1f}"
                    }),
                    use_container_width=True
                )
            else:
                st.success("æš‚æ— é«˜é£é™©å…³é”®è¯ï¼Œç­–ç•¥ç›®å‰å®‰å…¨ã€‚")

    # -----------------------------------------------------------
    # SCATTER PLOT (Visual Correlation)
    # -----------------------------------------------------------
    st.divider()
    st.subheader("ğŸ“ˆ æŠ•å…¥äº§å‡ºåˆ†å¸ƒå›¾ (Impact Distribution)")
    
    def categorize_outcome(row):
        if row['Pos_Delta'] < 0 and row['Imp_Delta'] > 0: return 'True Win'
        if row['CTR_Delta'] > 3 and row['Pos_Delta'] > 0: return 'Risk (Drop)'
        if row['CTR_Delta'] > 3 and row['Pos_Delta'] == 0: return 'Wasted'
        return 'Others'

    st_analysis_df['Category'] = st_analysis_df.apply(categorize_outcome, axis=1)

    fig_scatter = px.scatter(
        st_analysis_df,
        x='CTR_Delta',
        y='Pos_Delta',
        color='Category',
        hover_data=['Top_Queries', 'Impressions_B'],
        color_discrete_map={
            'True Win': 'green',
            'Risk (Drop)': 'red',
            'Wasted': 'gray',
            'Others': 'blue'
        },
        title="CTR æŠ•å…¥ (Xè½´) vs æ’åå˜åŒ– (Yè½´)"
    )
    fig_scatter.update_layout(
        yaxis_title="æ’åå˜åŒ– (è´Ÿæ•°=å˜å¥½)", 
        xaxis_title="CTR æå‡é‡ (%)",
        yaxis=dict(autorange="reversed") # Optional: make visual "up" mean rank up
    )
    st.plotly_chart(fig_scatter, use_container_width=True)