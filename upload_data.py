import streamlit as st
import pandas as pd
from supabase import create_client, Client
import streamlit as st

def check_password():
    """
    Ê£ÄÊü•ÂØÜÁ†ÅÊòØÂê¶Ê≠£Á°Æ„ÄÇ
    Â¶ÇÊûúÊ≠£Á°ÆÔºåËøîÂõû TrueÔºõÂ¶ÇÊûú‰∏çÊ≠£Á°ÆÔºåÊòæÁ§∫ËæìÂÖ•Ê°ÜÂπ∂ÂÅúÊ≠¢ËøêË°åÂêéÁª≠‰ª£Á†Å„ÄÇ
    """
    # 1. Â¶ÇÊûúÂ∑≤ÁªèÈ™åËØÅÊàêÂäüÔºåÁõ¥Êé•ËøîÂõû True
    if st.session_state.get("password_correct", False):
        return True

    # 2. ÂÆö‰πâÂØÜÁ†ÅÈ™åËØÅÁöÑÂõûË∞ÉÂáΩÊï∞
    def password_entered():
        # Ê£ÄÊü•ËæìÂÖ•ÂØÜÁ†ÅÊòØÂê¶ÂåπÈÖç Secrets ‰∏≠ÁöÑÈÖçÁΩÆ
        if st.session_state["password"] == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            # ‰∏∫‰∫ÜÂÆâÂÖ®ÔºåÈ™åËØÅÂêéÂà†Èô§ session ‰∏≠ÁöÑÊòéÊñáÂØÜÁ†Å
            del st.session_state["password"] 
        else:
            st.session_state["password_correct"] = False

    # 3. ÊòæÁ§∫ÂØÜÁ†ÅËæìÂÖ•Ê°Ü
    st.title("üîí ËØ∑ËæìÂÖ•ÂØÜÁ†ÅËÆøÈóÆ")
    st.text_input(
        "Password", 
        type="password", 
        on_change=password_entered, 
        key="password"
    )
    
    # 4. Â¶ÇÊûúÂØÜÁ†ÅÈîôËØØÔºåÊèêÁ§∫ÈîôËØØ
    if "password_correct" in st.session_state and not st.session_state["password_correct"]:
        st.error("üòï ÂØÜÁ†ÅÈîôËØØÔºåËØ∑ÈáçËØï„ÄÇ")

    # 5. ËøîÂõû FalseÔºåË°®Á§∫Êú™ÈÄöËøáÈ™åËØÅ
    return False

# --- ÊâßË°åÊ£ÄÊü• ---
if not check_password():
    st.stop()  # üõë Ê†∏ÂøÉÊ≠•È™§ÔºöÂ¶ÇÊûúÊ≤°ÈÄöËøáÔºåÁõ¥Êé•ÂÅúÊ≠¢ËøêË°å‰∏ãÈù¢ÁöÑÊâÄÊúâ‰ª£Á†Å

# -----------------------------------------------------------------------------
# 1. Supabase Connection Setup
# -----------------------------------------------------------------------------
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]

@st.cache_resource
def init_connection():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_connection()

# -----------------------------------------------------------------------------
# 2. Helper Functions
# -----------------------------------------------------------------------------
def get_or_create_domain_id(domain_name):
    """
    Checks the 'Domains' table for the domain name. 
    Returns the ID if found, or creates a new entry and returns the new ID.
    """
    try:
        # 1. Check if exists
        response = supabase.table('Domains').select("id").eq("domain_name", domain_name).execute()
        
        if response.data and len(response.data) > 0:
            return response.data[0]['id']
        else:
            # 2. Create new if not exists
            st.toast(f"New domain detected: {domain_name}. Creating ID...", icon="üÜï")
            insert_response = supabase.table('Domains').insert({"domain_name": domain_name}).execute()
            if insert_response.data:
                return insert_response.data[0]['id']
            else:
                raise Exception(f"Failed to create domain: {domain_name}")
                
    except Exception as e:
        st.error(f"Database Error resolving domain '{domain_name}'. Ensure your 'Domains' table has 'id' and 'domain_name' columns. Error: {e}")
        return None

def batch_insert(table_name, df, chunk_size=1000):
    """Inserts a pandas DataFrame into Supabase in chunks."""
    records = df.to_dict(orient='records')
    total_records = len(records)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, total_records, chunk_size):
        chunk = records[i:i + chunk_size]
        try:
            supabase.table(table_name).insert(chunk).execute()
            progress = min((i + chunk_size) / total_records, 1.0)
            progress_bar.progress(progress)
            status_text.text(f"Uploading... {min(i + chunk_size, total_records)} / {total_records} rows")
        except Exception as e:
            st.error(f"‚ùå Error inserting chunk {i}-{i+chunk_size}: {e}")
            return False
            
    status_text.success(f"‚úÖ Successfully uploaded {total_records} rows to '{table_name}'!")
    return True

# -----------------------------------------------------------------------------
# 3. Main Upload Interface
# -----------------------------------------------------------------------------
st.set_page_config(page_title="SEO Data Uploader", page_icon="üì§")

st.title("üì§ SEO Data Uploader")
st.markdown("This tool resolves Domain Names to IDs and inserts bulk CSV data.")
st.divider()

# --- Step 1: Configuration ---
st.subheader("1. Configuration")
table_option = st.selectbox("Select Target Table", ["GSC", "Top_Queries"])

st.divider()

# --- Step 2: Upload CSV ---
st.subheader("2. Upload CSV")
st.info("Your CSV must contain the columns: **Phase_id** (int) and a **Domain Name** column (e.g., 'Domain').")
uploaded_file = st.file_uploader(f"Choose a CSV file for {table_option}", type=['csv'])

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.write("### Data Preview")
        st.dataframe(df.head(3))

        # --- VALIDATION & PROCESSING ---
        
        # 1. Identify Domain Name Column
        domain_col_name = None
        possible_domain_headers = ['Domain', 'domain', 'Domain Name', 'domain_name']
        
        for col in df.columns:
            if col in possible_domain_headers:
                domain_col_name = col
                break
        
        if not domain_col_name:
            st.error("‚ùå CSV must contain a column for Domain Name (e.g., 'Domain', 'domain_name').")
            st.stop()
            
        if 'Phase_id' not in df.columns:
            st.error("‚ùå CSV must contain a column named 'Phase_id'.")
            st.stop()
        
        # 2. Domain Name Resolution (Map string names to Integer IDs)
        st.write("---")
        st.write("üîÑ **Resolving Domain Names to IDs...**")
        
        unique_domains = df[domain_col_name].astype(str).str.strip().unique()
        domain_map = {}
        
        for dom in unique_domains:
            if dom in ('', 'nan'): continue
            resolved_id = get_or_create_domain_id(dom)
            if resolved_id:
                domain_map[dom] = resolved_id
            else:
                st.stop() 
        
        # Apply the map to create the actual 'Domain_id' column
        df['Domain_id'] = df[domain_col_name].astype(str).str.strip().map(domain_map)
        
        if df['Domain_id'].isnull().any():
            st.error("Error mapping some domain names to IDs. Check for empty domain cells.")
            st.stop()
            
        st.success("‚úÖ All domains resolved to IDs successfully!")

        # 3. Column Cleanup and Formatting
        if table_option == "GSC":
            target_cols = ['Clicks', 'Impressions', 'Position', 'Date', 'Phase_id', 'Domain_id']
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
            else:
                st.error("‚ùå GSC data requires a 'Date' column.")
                st.stop()
        else:
            target_cols = ['Top_Queries', 'Clicks', 'Impressions', 'Position', 'Phase_id', 'Domain_id']

        missing = [c for c in target_cols if c not in df.columns]
        if missing:
            st.error(f"‚ùå Missing columns for database insert: {missing}")
            st.stop()

        df_final = df[target_cols]

        # --- Step 4: Confirm & Upload ---
        st.write("---")
        st.warning(f"Ready to upload {len(df_final)} rows to **{table_option}**.")
        
        if st.button("üöÄ Confirm and Upload Data"):
            with st.spinner("Processing upload..."):
                batch_insert(table_option, df_final)

    except Exception as e:
        st.error(f"An unexpected error occurred. Check data types in CSV. Error: {e}")